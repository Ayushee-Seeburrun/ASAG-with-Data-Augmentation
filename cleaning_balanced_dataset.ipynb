{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUx8fhDnNZsIYm+DKfQM9H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayushee-Seeburrun/ASAG-with-Data-Augmentation/blob/main/cleaning_balanced_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGozXexKvzx1",
        "outputId": "e9463c87-2408-4b11-9b24-7924a21fee65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re, unicodedata\n",
        "\n",
        "INFILE  = \"/content/drive/MyDrive/Data Augmentation/Dataset Splits/train_balanced_final.csv\"\n",
        "#OUTFILE = \"/content/drive/MyDrive/Data Augmentation/Dataset Splits/train_balanced_clean.csv\"\n",
        "\n",
        "def norm_text(s):\n",
        "    s = str(s)\n",
        "    s = unicodedata.normalize(\"NFKC\", s)\n",
        "    s = s.replace(\"\\u00A0\", \" \")\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "df = pd.read_csv(INFILE)\n",
        "df[\"type\"] = df[\"type\"].fillna(\"\").astype(str).str.strip().str.lower()\n",
        "df[\"EssayText\"] = df[\"EssayText\"].map(norm_text)\n",
        "\n",
        "orig = df[df[\"type\"] != \"paraphrased\"].copy()\n",
        "para = df[df[\"type\"] == \"paraphrased\"].copy()\n",
        "\n",
        "#here ^p are removed from the records(paraphrases only)\n",
        "para = para[~para[\"EssayText\"].str.lower().str.contains(r\"\\^p\", na=False)]\n",
        "\n",
        "#removing non-english sentences generated by claude during the balancing process\n",
        "danish_pat = r\"([æøå]|\\bhvis\\b|\\bvil\\b|\\bjeg\\b|\\bfordi\\b|\\bder\\b|\\bdet\\b|\\bvære\\b|\\bnår\\b|\\bikke\\b)\"\n",
        "para = para[~para[\"EssayText\"].str.lower().str.contains(danish_pat, regex=True, na=False)]\n",
        "\n",
        "#remove paraphrase duplicates (per score, normalized)\n",
        "para[\"_norm\"] = para[\"EssayText\"].map(norm_text)\n",
        "para = para.drop_duplicates(subset=[\"Score2\", \"_norm\"], keep=\"first\").drop(columns=[\"_norm\"])\n",
        "\n",
        "cleaned = pd.concat([orig, para], ignore_index=True)\n",
        "\n",
        "print(\"Before:\", len(df), \"| After:\", len(cleaned))\n",
        "print(\"Type counts:\\n\", cleaned[\"type\"].value_counts(dropna=False))\n",
        "print(\"Score counts:\\n\", cleaned[\"Score2\"].value_counts().sort_index())\n",
        "\n",
        "#cleaned.to_csv(OUTFILE, index=False)\n",
        "#print(\"Saved cleaned base dataset to:\", OUTFILE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIh6AiHMx2MZ",
        "outputId": "ef6311f8-b840-4853-e4d8-4c74b273695d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-491861055.py:26: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  para = para[~para[\"EssayText\"].str.lower().str.contains(danish_pat, regex=True, na=False)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: 17252 | After: 17225\n",
            "Type counts:\n",
            " type\n",
            "               13765\n",
            "paraphrased     3460\n",
            "Name: count, dtype: int64\n",
            "Score counts:\n",
            " Score2\n",
            "0    5424\n",
            "1    4518\n",
            "2    4194\n",
            "3    3089\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here - reordering how the records are saved in the dataste, the originals first and then wwe have the paraphrased\n",
        "import pandas as pd\n",
        "\n",
        "INFILE  = \"/content/drive/MyDrive/Data Augmentation/Dataset Splits/train_balanced_clean.csv\"\n",
        "#OUTFILE = \"/content/drive/MyDrive/Data Augmentation/Dataset Splits/train_balanced_clean.csv\"\n",
        "\n",
        "df = pd.read_csv(INFILE)\n",
        "\n",
        "df[\"type\"] = df[\"type\"].fillna(\"\").astype(str).str.strip().str.lower()\n",
        "\n",
        "#splitting  into original and paraphrased\n",
        "orig = df[df[\"type\"] != \"paraphrased\"].copy()\n",
        "para = df[df[\"type\"] == \"paraphrased\"].copy()\n",
        "\n",
        "#ensure paraphrased rows have type \"paraphrased\"\n",
        "para[\"type\"] = \"paraphrased\"\n",
        "\n",
        "#sort paraphrases by score\n",
        "para = para.sort_values(by=[\"Score2\"], ascending=True).reset_index(drop=True)\n",
        "\n",
        "#originals first, paraphrases appended afterwards\n",
        "final_df = pd.concat([orig.reset_index(drop=True), para], ignore_index=True)\n",
        "\n",
        "#final_df.to_csv(OUTFILE, index=False)\n",
        "\n",
        "#print(\"Saved:\", OUTFILE)\n",
        "print(\"Rows:\", len(final_df))\n",
        "print(\"Type counts:\\n\", final_df[\"type\"].value_counts(dropna=False))\n",
        "print(\"Score counts:\\n\", final_df[\"Score2\"].value_counts().sort_index())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvGsrHrBF-3b",
        "outputId": "ddb79ddc-88e0-4215-edb9-5833da666221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 17225\n",
            "Type counts:\n",
            " type\n",
            "               13765\n",
            "paraphrased     3460\n",
            "Name: count, dtype: int64\n",
            "Score counts:\n",
            " Score2\n",
            "0    5424\n",
            "1    4518\n",
            "2    4194\n",
            "3    3089\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Final cleaned and balanced dataset: \\n\", cleaned[\"Score2\"].value_counts().sort_index(), \"\\n\", final_df[\"Score2\"].value_counts().sort_index())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdTq6rLbALjF",
        "outputId": "2a860837-040e-4292-ee3d-3914d4eacae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final cleaned and balanced dataset: \n",
            " Score2\n",
            "0    5424\n",
            "1    4518\n",
            "2    4194\n",
            "3    3089\n",
            "Name: count, dtype: int64 \n",
            " Score2\n",
            "0    5424\n",
            "1    4518\n",
            "2    4194\n",
            "3    3089\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}